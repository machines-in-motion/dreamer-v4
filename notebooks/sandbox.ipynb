{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bef3906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py \n",
    "import torch \n",
    "import numpy as np\n",
    "from torch.nn.functional import interpolate\n",
    "from pathlib import Path\n",
    "\n",
    "input_dir = '/home/mim-server/datasets/pushT/224/'\n",
    "output_dir = '/home/mim-server/datasets/pushT/sharded/'\n",
    "input_files = os.listdir(input_dir)\n",
    "shard_file = input_files[0]  \n",
    "\n",
    "input_data_path = os.path.join(input_dir, shard_file)\n",
    "output_dir = Path(output_dir)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def loadPushTData(data_path):\n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        data = f\n",
    "        actions = data['actions'][:]\n",
    "        images = data['cam1'][:]\n",
    "    images = torch.from_numpy(images).float()\n",
    "    images = interpolate(images, size=(256,256), mode='bilinear', align_corners=False)\n",
    "    images = images.permute(0, 2, 3, 1)  # NHWC to NCHW\n",
    "    images = (images*255).to(torch.uint8)\n",
    "    return actions[None], images[None].numpy()\n",
    "\n",
    "def saveShardedData(output_path, actions, images):\n",
    "    with h5py.File(output_path, 'w') as f:\n",
    "        comp_args = {'compression': 'gzip', 'compression_opts': 4}\n",
    "        image_shape = images.shape[2:]\n",
    "        action_shape = actions.shape[2:]\n",
    "        images_ds = f.create_dataset('images', shape=images.shape, dtype=np.uint8, chunks=(1, 128, *image_shape), **comp_args)\n",
    "        actions_ds = f.create_dataset('actions', shape=actions.shape, dtype=np.float32, chunks=(1, 128, *action_shape), **comp_args)\n",
    "        f.create_dataset('episode_lengths', data=np.array([images.shape[1]], dtype=np.int32))\n",
    "        f.attrs['num_episodes'] = images.shape[1]\n",
    "        images_ds[:] = images\n",
    "        actions_ds[:] = actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b7c9d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1/13: episode_3.h5\n",
      "  Loaded data shape - actions: (1, 6609, 3), images: (1, 6609, 256, 256, 3)\n",
      "Processing file 2/13: episode_7.h5\n",
      "  Loaded data shape - actions: (1, 6013, 3), images: (1, 6013, 256, 256, 3)\n",
      "Processing file 3/13: episode_9.h5\n",
      "  Loaded data shape - actions: (1, 4513, 3), images: (1, 4513, 256, 256, 3)\n",
      "Processing file 4/13: episode_11.h5\n",
      "  Loaded data shape - actions: (1, 6014, 3), images: (1, 6014, 256, 256, 3)\n",
      "Processing file 5/13: episode_8.h5\n",
      "  Loaded data shape - actions: (1, 6014, 3), images: (1, 6014, 256, 256, 3)\n",
      "Processing file 6/13: episode_4.h5\n",
      "  Loaded data shape - actions: (1, 6183, 3), images: (1, 6183, 256, 256, 3)\n",
      "Processing file 7/13: episode_12.h5\n",
      "  Loaded data shape - actions: (1, 6013, 3), images: (1, 6013, 256, 256, 3)\n",
      "Processing file 8/13: episode_5.h5\n",
      "  Loaded data shape - actions: (1, 5631, 3), images: (1, 5631, 256, 256, 3)\n",
      "Processing file 9/13: episode_1.h5\n",
      "  Loaded data shape - actions: (1, 6310, 3), images: (1, 6310, 256, 256, 3)\n",
      "Processing file 10/13: episode_2.h5\n",
      "  Loaded data shape - actions: (1, 6297, 3), images: (1, 6297, 256, 256, 3)\n",
      "Processing file 11/13: episode_6.h5\n",
      "  Loaded data shape - actions: (1, 6014, 3), images: (1, 6014, 256, 256, 3)\n",
      "Processing file 12/13: episode_10.h5\n",
      "  Loaded data shape - actions: (1, 6013, 3), images: (1, 6013, 256, 256, 3)\n",
      "Processing file 13/13: episode_0.h5\n",
      "  Loaded data shape - actions: (1, 6074, 3), images: (1, 6074, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "for i, data_file in enumerate(input_files):\n",
    "    print(f\"Processing file {i+1}/{len(input_files)}: {data_file}\")\n",
    "    input_data_path = os.path.join(input_dir, data_file)\n",
    "    output_data_path = os.path.join(output_dir, f\"shard_{i:04d}.h5\")\n",
    "    actions, images = loadPushTData(input_data_path)\n",
    "    print(f\"  Loaded data shape - actions: {actions.shape}, images: {images.shape}\")\n",
    "    saveShardedData(output_data_path, actions, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6c8efff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mim-server/datasets/pushT/sharded'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d71e764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split: 0 windows from 0 episodes\n"
     ]
    }
   ],
   "source": [
    "from dreamerv4.datasets import ShardedHDF5Dataset\n",
    "\n",
    "dataset = ShardedHDF5Dataset(str(output_dir), window_size=192, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9f1e705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mim-server/miniconda3/envs/dreamerv4/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'dynamics/pushT.yaml': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from dreamerv4.datasets import ShardedHDF5Dataset\n",
    "from dreamerv4.models.utils import load_tokenizer\n",
    "from dreamerv4.models.utils import load_denoiser\n",
    "from dreamerv4.models.dynamics import DenoiserWrapper\n",
    "from dreamerv4.models.tokenizer import TokenizerWrapper\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "with initialize(version_base=None, config_path=\"scripts/config\"):\n",
    "    cfg = compose(config_name=\"dynamics/pushT.yaml\")\n",
    "\n",
    "model = DenoiserWrapper(cfg)\n",
    "# model = TokenizerWrapper(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56980bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'global_update', 'model', 'optim', 'scheduler', 'wandb_run_id', 'log_dir'])\n",
      "dict_keys(['model.register_tokens', 'model.action_tokens', 'model.diffusion_embedder.embeddings', 'model.shortcut_embedder.embeddings', 'model.layers.0.layers.0.attn.attn.W_q.weight', 'model.layers.0.layers.0.attn.attn.W_k.weight', 'model.layers.0.layers.0.attn.attn.W_v.weight', 'model.layers.0.layers.0.attn.attn.W_o.weight', 'model.layers.0.layers.0.norm1.weight', 'model.layers.0.layers.0.norm2.weight', 'model.layers.0.layers.0.ffn.up.weight', 'model.layers.0.layers.0.ffn.gate.weight', 'model.layers.0.layers.0.ffn.down.weight', 'model.layers.0.layers.1.attn.attn.W_q.weight', 'model.layers.0.layers.1.attn.attn.W_k.weight', 'model.layers.0.layers.1.attn.attn.W_v.weight', 'model.layers.0.layers.1.attn.attn.W_o.weight', 'model.layers.0.layers.1.norm1.weight', 'model.layers.0.layers.1.norm2.weight', 'model.layers.0.layers.1.ffn.up.weight', 'model.layers.0.layers.1.ffn.gate.weight', 'model.layers.0.layers.1.ffn.down.weight', 'model.layers.0.layers.2.attn.attn.W_q.weight', 'model.layers.0.layers.2.attn.attn.W_k.weight', 'model.layers.0.layers.2.attn.attn.W_v.weight', 'model.layers.0.layers.2.attn.attn.W_o.weight', 'model.layers.0.layers.2.norm1.weight', 'model.layers.0.layers.2.norm2.weight', 'model.layers.0.layers.2.ffn.up.weight', 'model.layers.0.layers.2.ffn.gate.weight', 'model.layers.0.layers.2.ffn.down.weight', 'model.layers.0.layers.3.attn.attn.W_q.weight', 'model.layers.0.layers.3.attn.attn.W_k.weight', 'model.layers.0.layers.3.attn.attn.W_v.weight', 'model.layers.0.layers.3.attn.attn.W_o.weight', 'model.layers.0.layers.3.norm1.weight', 'model.layers.0.layers.3.norm2.weight', 'model.layers.0.layers.3.ffn.up.weight', 'model.layers.0.layers.3.ffn.gate.weight', 'model.layers.0.layers.3.ffn.down.weight', 'model.layers.1.layers.0.attn.attn.W_q.weight', 'model.layers.1.layers.0.attn.attn.W_k.weight', 'model.layers.1.layers.0.attn.attn.W_v.weight', 'model.layers.1.layers.0.attn.attn.W_o.weight', 'model.layers.1.layers.0.norm1.weight', 'model.layers.1.layers.0.norm2.weight', 'model.layers.1.layers.0.ffn.up.weight', 'model.layers.1.layers.0.ffn.gate.weight', 'model.layers.1.layers.0.ffn.down.weight', 'model.layers.1.layers.1.attn.attn.W_q.weight', 'model.layers.1.layers.1.attn.attn.W_k.weight', 'model.layers.1.layers.1.attn.attn.W_v.weight', 'model.layers.1.layers.1.attn.attn.W_o.weight', 'model.layers.1.layers.1.norm1.weight', 'model.layers.1.layers.1.norm2.weight', 'model.layers.1.layers.1.ffn.up.weight', 'model.layers.1.layers.1.ffn.gate.weight', 'model.layers.1.layers.1.ffn.down.weight', 'model.layers.1.layers.2.attn.attn.W_q.weight', 'model.layers.1.layers.2.attn.attn.W_k.weight', 'model.layers.1.layers.2.attn.attn.W_v.weight', 'model.layers.1.layers.2.attn.attn.W_o.weight', 'model.layers.1.layers.2.norm1.weight', 'model.layers.1.layers.2.norm2.weight', 'model.layers.1.layers.2.ffn.up.weight', 'model.layers.1.layers.2.ffn.gate.weight', 'model.layers.1.layers.2.ffn.down.weight', 'model.layers.1.layers.3.attn.attn.W_q.weight', 'model.layers.1.layers.3.attn.attn.W_k.weight', 'model.layers.1.layers.3.attn.attn.W_v.weight', 'model.layers.1.layers.3.attn.attn.W_o.weight', 'model.layers.1.layers.3.norm1.weight', 'model.layers.1.layers.3.norm2.weight', 'model.layers.1.layers.3.ffn.up.weight', 'model.layers.1.layers.3.ffn.gate.weight', 'model.layers.1.layers.3.ffn.down.weight', 'model.layers.2.layers.0.attn.attn.W_q.weight', 'model.layers.2.layers.0.attn.attn.W_k.weight', 'model.layers.2.layers.0.attn.attn.W_v.weight', 'model.layers.2.layers.0.attn.attn.W_o.weight', 'model.layers.2.layers.0.norm1.weight', 'model.layers.2.layers.0.norm2.weight', 'model.layers.2.layers.0.ffn.up.weight', 'model.layers.2.layers.0.ffn.gate.weight', 'model.layers.2.layers.0.ffn.down.weight', 'model.layers.2.layers.1.attn.attn.W_q.weight', 'model.layers.2.layers.1.attn.attn.W_k.weight', 'model.layers.2.layers.1.attn.attn.W_v.weight', 'model.layers.2.layers.1.attn.attn.W_o.weight', 'model.layers.2.layers.1.norm1.weight', 'model.layers.2.layers.1.norm2.weight', 'model.layers.2.layers.1.ffn.up.weight', 'model.layers.2.layers.1.ffn.gate.weight', 'model.layers.2.layers.1.ffn.down.weight', 'model.layers.2.layers.2.attn.attn.W_q.weight', 'model.layers.2.layers.2.attn.attn.W_k.weight', 'model.layers.2.layers.2.attn.attn.W_v.weight', 'model.layers.2.layers.2.attn.attn.W_o.weight', 'model.layers.2.layers.2.norm1.weight', 'model.layers.2.layers.2.norm2.weight', 'model.layers.2.layers.2.ffn.up.weight', 'model.layers.2.layers.2.ffn.gate.weight', 'model.layers.2.layers.2.ffn.down.weight', 'model.layers.2.layers.3.attn.attn.W_q.weight', 'model.layers.2.layers.3.attn.attn.W_k.weight', 'model.layers.2.layers.3.attn.attn.W_v.weight', 'model.layers.2.layers.3.attn.attn.W_o.weight', 'model.layers.2.layers.3.norm1.weight', 'model.layers.2.layers.3.norm2.weight', 'model.layers.2.layers.3.ffn.up.weight', 'model.layers.2.layers.3.ffn.gate.weight', 'model.layers.2.layers.3.ffn.down.weight', 'model.layers.3.layers.0.attn.attn.W_q.weight', 'model.layers.3.layers.0.attn.attn.W_k.weight', 'model.layers.3.layers.0.attn.attn.W_v.weight', 'model.layers.3.layers.0.attn.attn.W_o.weight', 'model.layers.3.layers.0.norm1.weight', 'model.layers.3.layers.0.norm2.weight', 'model.layers.3.layers.0.ffn.up.weight', 'model.layers.3.layers.0.ffn.gate.weight', 'model.layers.3.layers.0.ffn.down.weight', 'model.layers.3.layers.1.attn.attn.W_q.weight', 'model.layers.3.layers.1.attn.attn.W_k.weight', 'model.layers.3.layers.1.attn.attn.W_v.weight', 'model.layers.3.layers.1.attn.attn.W_o.weight', 'model.layers.3.layers.1.norm1.weight', 'model.layers.3.layers.1.norm2.weight', 'model.layers.3.layers.1.ffn.up.weight', 'model.layers.3.layers.1.ffn.gate.weight', 'model.layers.3.layers.1.ffn.down.weight', 'model.layers.3.layers.2.attn.attn.W_q.weight', 'model.layers.3.layers.2.attn.attn.W_k.weight', 'model.layers.3.layers.2.attn.attn.W_v.weight', 'model.layers.3.layers.2.attn.attn.W_o.weight', 'model.layers.3.layers.2.norm1.weight', 'model.layers.3.layers.2.norm2.weight', 'model.layers.3.layers.2.ffn.up.weight', 'model.layers.3.layers.2.ffn.gate.weight', 'model.layers.3.layers.2.ffn.down.weight', 'model.layers.3.layers.3.attn.attn.W_q.weight', 'model.layers.3.layers.3.attn.attn.W_k.weight', 'model.layers.3.layers.3.attn.attn.W_v.weight', 'model.layers.3.layers.3.attn.attn.W_o.weight', 'model.layers.3.layers.3.norm1.weight', 'model.layers.3.layers.3.norm2.weight', 'model.layers.3.layers.3.ffn.up.weight', 'model.layers.3.layers.3.ffn.gate.weight', 'model.layers.3.layers.3.ffn.down.weight', 'model.latent_projector.weight', 'model.output_projector.weight', 'model.diff_control_proj.weight', 'model.action_proj.weight', 'model.action_proj.bias'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "ckpt_path = \"/home/mim-server/projects/rooholla/dreamer-v4-draft/checkpoints/dynamics_ckpts/video-pushT-110M.pt\"\n",
    "state = torch.load(ckpt_path, map_location='cpu')\n",
    "if 'dyn' in state.keys():\n",
    "    sd = state['dyn']\n",
    "else:\n",
    "    sd = state['model']\n",
    "    \n",
    "to_delete = []\n",
    "clean_sd = {k.replace(\"_orig_mod.\", \"\"): v for k, v in sd.items()}\n",
    "for k in clean_sd.keys():\n",
    "    if k.endswith(\"cos_emb\") or k.endswith(\"sin_emb\") or \"temporal_mask_full\" in k:\n",
    "        to_delete.append(k)\n",
    "for k in to_delete:\n",
    "    del clean_sd[k]\n",
    "\n",
    "spell_corrrected = {}\n",
    "for key in clean_sd.keys():\n",
    "    val = clean_sd[key]\n",
    "    if 'diffuion' in key:\n",
    "        key = key.replace('diffuion', 'diffusion')\n",
    "        print(key)\n",
    "\n",
    "    spell_corrrected[key]=val\n",
    "\n",
    "clean_sd = spell_corrrected\n",
    "\n",
    "state['model'] = clean_sd\n",
    "if 'model' not in state.keys():\n",
    "    clean_sd = {'model.'+k: v for k, v in clean_sd.items()}\n",
    "    state['model'] = clean_sd\n",
    "if 'dyn' in state.keys():\n",
    "    del state['dyn']\n",
    "\n",
    "\n",
    "\n",
    "print(state.keys())\n",
    "print(state['model'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42c47742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state['model'], strict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbebcbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(state, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b17088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreamerv4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
